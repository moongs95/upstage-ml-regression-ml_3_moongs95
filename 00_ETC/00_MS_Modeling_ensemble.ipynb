{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e35fd8db-1550-47c4-b451-3f28a81980c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.9 MB 16.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas!=2.1.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (2.0.3)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (1.24.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (1.10.1)\n",
      "Collecting patsy>=0.5.4\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "\u001b[K     |████████████████████████████████| 232 kB 151.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.0->statsmodels) (1.17.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-1.0.1 statsmodels-0.14.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install bayesian-optimizatio\n",
    "# !pip install optuna\n",
    "# !pip install --upgrade lightgbm\n",
    "!pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13a432e4-d688-4669-aba1-a6f14ce5a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from lightgbm import LGBMRegressor, early_stopping, LGBMClassifier, log_evaluation\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "import optuna\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# 2) 한글 폰트 설정 (예: 나눔고딕)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "# 시스템에 나눔고딕이 설치되어 있어야 합니다.\n",
    "rc('font', family='NanumGothic')  \n",
    "# 마이너스 기호가 깨지는 경우\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d23e598-2f33-4622-b2f5-008804a20f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train = pd.read_csv(\"train_2020.csv\")\n",
    "test  = pd.read_csv(\"test_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c00bc6a9-b532-422b-87ce-96da7fa36c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   feature           VIF\n",
      "0                    const  0.000000e+00\n",
      "1                       본번  1.156750e+00\n",
      "2                       부번  1.019265e+00\n",
      "3                  전용면적(㎡)           inf\n",
      "4                     계약년월           inf\n",
      "5                      계약일  1.002724e+00\n",
      "6                     건축년도  1.149170e+05\n",
      "7                   k-전체동수  5.340122e+00\n",
      "8                  k-전체세대수  5.890091e+01\n",
      "9                    k-연면적  5.768388e+00\n",
      "10                k-주거전용면적  7.384033e+01\n",
      "11               k-관리비부과면적  6.244331e+01\n",
      "12      k-전용면적별세대현황(60㎡이하)  9.964373e+00\n",
      "13  k-전용면적별세대현황(60㎡~85㎡이하)  5.468459e+00\n",
      "14            k-85㎡~135㎡이하  2.289285e+00\n",
      "15                    건축면적  1.067391e+00\n",
      "16                    주차대수  2.918490e+00\n",
      "17                     계약년           inf\n",
      "18                     계약월           inf\n",
      "19                     x좌표  1.741527e+00\n",
      "20                     y좌표  2.476287e+00\n",
      "21               전용면적(log)  8.682049e+00\n",
      "22                      평수           inf\n",
      "23                      연식  1.137592e+05\n",
      "24              신축(10년 미만)  2.503852e+00\n",
      "25          재건축 연한(30년 이상)  2.491041e+00\n",
      "26                   강남권여부  4.543284e+00\n",
      "27                    우수학군  2.522656e+00\n",
      "28                 프리미엄아파트  1.534419e+00\n",
      "29                 대장아파트거리  1.628390e+01\n",
      "30            대장아파트거리(log)  1.429983e+01\n",
      "31                   회사채금리           inf\n",
      "32                  매매가격지수  1.387941e+01\n",
      "33                 건설공사비지수  1.791809e+01\n",
      "34                     거래량  1.617298e+00\n",
      "35                 회사채금리t3           inf\n",
      "36                 회사채금리t6           inf\n",
      "37                  delta3           inf\n",
      "38                  delta6           inf\n",
      "39                     MA3  2.074849e+02\n",
      "40                     MA6  4.459024e+02\n",
      "41                    버스거리  1.158635e+01\n",
      "42                   지하철거리  5.785920e+00\n",
      "43               1km이내지하철수  1.536471e+00\n",
      "44                  지하철접근성  5.072683e+00\n",
      "45                1km이내학교수  1.492301e+00\n",
      "46                  초등학교거리  1.557742e+01\n",
      "47                초등학교거리구분  4.145665e+00\n",
      "48                 고등학교진학률  2.531308e+00\n",
      "49       elite_min_dist_km  2.832285e+00\n",
      "50          elite_cnt_1.5k  2.874694e+00\n",
      "51          elite_cnt_2.0k  2.516388e+00\n",
      "52       target_prev3month  2.710509e+00\n",
      "53                 계약년월가중치           inf\n",
      "54       target_prev6month  3.104816e+00\n"
     ]
    }
   ],
   "source": [
    "# 타깃 제외 후 숫자형 피처만 선택\n",
    "X = train.drop(columns=['target'])\n",
    "X_numeric = X.select_dtypes(include=[float, int])\n",
    "\n",
    "# 상수항 추가\n",
    "import statsmodels.api as sm\n",
    "X_const = sm.add_constant(X_numeric)\n",
    "\n",
    "# VIF 계산\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X_const.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]\n",
    "\n",
    "print(vif_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fb4bc14-fb8f-41b1-8454-f6fa33a13260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 516845 entries, 0 to 516844\n",
      "Data columns (total 92 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   시군구                     516845 non-null  object \n",
      " 1   번지                      516845 non-null  object \n",
      " 2   본번                      516845 non-null  float64\n",
      " 3   부번                      516845 non-null  float64\n",
      " 4   아파트명                    516845 non-null  object \n",
      " 5   전용면적(㎡)                 516845 non-null  float64\n",
      " 6   계약년월                    516845 non-null  int64  \n",
      " 7   계약일                     516845 non-null  int64  \n",
      " 8   층                       516845 non-null  object \n",
      " 9   건축년도                    516845 non-null  int64  \n",
      " 10  도로명                     516845 non-null  object \n",
      " 11  등기신청일자                  516845 non-null  object \n",
      " 12  거래유형                    516845 non-null  object \n",
      " 13  중개사소재지                  516845 non-null  object \n",
      " 14  k-단지분류(아파트,주상복합등등)      516845 non-null  object \n",
      " 15  k-전화번호                  516845 non-null  object \n",
      " 16  k-팩스번호                  516845 non-null  object \n",
      " 17  k-세대타입(분양형태)            516845 non-null  object \n",
      " 18  k-관리방식                  516845 non-null  object \n",
      " 19  k-복도유형                  516845 non-null  object \n",
      " 20  k-난방방식                  516845 non-null  object \n",
      " 21  k-전체동수                  516845 non-null  float64\n",
      " 22  k-전체세대수                 516845 non-null  float64\n",
      " 23  k-건설사(시공사)              516845 non-null  object \n",
      " 24  k-시행사                   516845 non-null  object \n",
      " 25  k-사용검사일-사용승인일           516845 non-null  object \n",
      " 26  k-연면적                   516845 non-null  float64\n",
      " 27  k-주거전용면적                516845 non-null  float64\n",
      " 28  k-관리비부과면적               516845 non-null  float64\n",
      " 29  k-전용면적별세대현황(60㎡이하)      516845 non-null  float64\n",
      " 30  k-전용면적별세대현황(60㎡~85㎡이하)  516845 non-null  float64\n",
      " 31  k-85㎡~135㎡이하            516845 non-null  float64\n",
      " 32  k-수정일자                  516845 non-null  object \n",
      " 33  경비비관리형태                 516845 non-null  object \n",
      " 34  세대전기계약방법                516845 non-null  object \n",
      " 35  청소비관리형태                 516845 non-null  object \n",
      " 36  건축면적                    516845 non-null  float64\n",
      " 37  주차대수                    516845 non-null  float64\n",
      " 38  기타/의무/임대/임의=1/2/3/4     516845 non-null  object \n",
      " 39  단지승인일                   516845 non-null  object \n",
      " 40  사용허가여부                  516845 non-null  object \n",
      " 41  관리비 업로드                 516845 non-null  object \n",
      " 42  단지신청일                   516845 non-null  object \n",
      " 43  계약년                     516845 non-null  int64  \n",
      " 44  계약월                     516845 non-null  int64  \n",
      " 45  브랜드명                    516845 non-null  object \n",
      " 46  구                       516845 non-null  object \n",
      " 47  주소                      516845 non-null  object \n",
      " 48  x좌표                     516845 non-null  float64\n",
      " 49  y좌표                     516845 non-null  float64\n",
      " 50  전용면적(log)               516845 non-null  float64\n",
      " 51  전용면적구간                  516845 non-null  object \n",
      " 52  평수                      516845 non-null  float64\n",
      " 53  연식                      516845 non-null  int64  \n",
      " 54  신축(10년 미만)              516845 non-null  int64  \n",
      " 55  재건축 연한(30년 이상)          516845 non-null  int64  \n",
      " 56  강남권여부                   516845 non-null  int64  \n",
      " 57  우수학군                    516845 non-null  int64  \n",
      " 58  프리미엄아파트                 516845 non-null  int64  \n",
      " 59  zone4                   516845 non-null  object \n",
      " 60  zone4_강남3               516845 non-null  bool   \n",
      " 61  zone4_내부권               516845 non-null  bool   \n",
      " 62  zone4_도심                516845 non-null  bool   \n",
      " 63  zone4_외곽                516845 non-null  bool   \n",
      " 64  대장아파트거리                 516845 non-null  float64\n",
      " 65  대장아파트거리(log)            516845 non-null  float64\n",
      " 66  대장아파트거리접근성              516845 non-null  object \n",
      " 67  회사채금리                   516845 non-null  float64\n",
      " 68  매매가격지수                  516845 non-null  float64\n",
      " 69  건설공사비지수                 516845 non-null  float64\n",
      " 70  거래량                     516845 non-null  int64  \n",
      " 71  회사채금리t3                 516845 non-null  float64\n",
      " 72  회사채금리t6                 516845 non-null  float64\n",
      " 73  delta3                  516845 non-null  float64\n",
      " 74  delta6                  516845 non-null  float64\n",
      " 75  MA3                     516845 non-null  float64\n",
      " 76  MA6                     516845 non-null  float64\n",
      " 77  버스거리                    516845 non-null  float64\n",
      " 78  지하철거리                   516845 non-null  float64\n",
      " 79  1km이내지하철수               516845 non-null  int64  \n",
      " 80  지하철접근성                  516845 non-null  int64  \n",
      " 81  1km이내학교수                516845 non-null  int64  \n",
      " 82  초등학교거리                  516845 non-null  float64\n",
      " 83  초등학교거리구분                516845 non-null  int64  \n",
      " 84  고등학교진학률                 516845 non-null  float64\n",
      " 85  elite_min_dist_km       516845 non-null  float64\n",
      " 86  elite_cnt_1.5k          516845 non-null  int64  \n",
      " 87  elite_cnt_2.0k          516845 non-null  int64  \n",
      " 88  target_prev3month       516845 non-null  float64\n",
      " 89  계약년월가중치                 516845 non-null  int64  \n",
      " 90  target_prev6month       516845 non-null  float64\n",
      " 91  target                  516845 non-null  int64  \n",
      "dtypes: bool(4), float64(35), int64(20), object(33)\n",
      "memory usage: 349.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# 데이터 feature 확인 \n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fca8ab92-77ee-4cb4-b413-a8652b2687b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def except_cols(df):\n",
    "    df = df.drop(['번지', '본번', '부번', '계약일', '도로명', '중개사소재지', 'k-전화번호', 'k-팩스번호', 'k-관리방식',\n",
    "                  'k-사용검사일-사용승인일', '경비비관리형태', '세대전기계약방법', '청소비관리형태', 'k-수정일자',\n",
    "                  '계약년', '계약월', '주소'], axis=1)\n",
    "    return df\n",
    "\n",
    "# 도메인 기반 필요없는 열 제거\n",
    "train = except_cols(train)\n",
    "test = except_cols(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdb0527e-2826-4545-9b75-6d9006a51635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = {'일반': 0, '고가': 1}\n",
    "# train['구_그룹'] = train['구_그룹'].map(mapping).astype(int)\n",
    "# test['구_그룹'] = test['구_그룹'].map(mapping).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bfd537e-d597-4849-b92a-9563eb4aee9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 사용할 컬럼명 리스트 정의 (필요에 따라 here에 컬럼명 추가/삭제)\n",
    "# use_columns = ['전용면적(㎡)', '건축년도',  '매매가격지수', '건설공사비지수',\n",
    "#     '버스정류장수', '지하철수', '연식', '대장아파트거리', '강남권여부', \n",
    "#     '버스거리', '지하철거리',  '초등학교거리', '1km이내학교수', '회사채금리',\n",
    "#     '고등학교진학률', '층', 'delta3', 'delta6', 'MA6', '지하철접근성', '평수']\n",
    "# #  '구', '계약년월', '아파트명', '전용면적(log)', '대장아파트거리(log)', 'MA3','거래량', 'delta12' , '구_그룹'\n",
    "# 1. feature/target 분리\n",
    "y_train = train['target'].values\n",
    "\n",
    "# 피처 데이터 분리\n",
    "X_train_df = train.drop(columns=['target']).copy()\n",
    "X_test_df = test.copy()\n",
    "\n",
    "# 범주형 컬럼 추출\n",
    "cat_cols = X_train_df.select_dtypes(include=['object', 'category']).columns\n",
    "le_dict = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X_train_df[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "\n",
    "    # train 데이터는 그대로 transform\n",
    "    X_train_df[col] = le.transform(X_train_df[col].astype(str))\n",
    "\n",
    "    # test 데이터는 unseen 라벨을 -1로 처리\n",
    "    X_test_df[col] = X_test_df[col].astype(str).map(lambda x: x if x in le.classes_ else -1)\n",
    "\n",
    "    # transform 가능한 값들만 LabelEncoder로 인코딩, -1은 그대로 유지\n",
    "    valid_mask = X_test_df[col] != -1\n",
    "    # 임시 배열 선언\n",
    "    temp = np.full(X_test_df.shape[0], -1)\n",
    "    temp[valid_mask] = le.transform(X_test_df.loc[valid_mask, col])\n",
    "    X_test_df[col] = temp\n",
    "\n",
    "# # 범주형 인코딩 (train)\n",
    "# for col in cat_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     X_train_df[col] = le.fit_transform(X_train_df[col])\n",
    "#     le_dict[col] = le\n",
    "\n",
    "# # # val/test가 별도 데이터면 val 데이터에도 동일한 변환 적용 (아래는 val이 있을 경우)\n",
    "# # X_val_df = val.copy()\n",
    "# # for col in cat_cols:\n",
    "# #     le = le_dict[col]\n",
    "# #     X_val_df[col] = X_val_df[col].map(lambda x: x if x in le.classes_ else None)\n",
    "# #     X_val_df[col] = X_val_df[col].fillna(le.classes_[0])\n",
    "# #     X_val_df[col] = le.transform(X_val_df[col])\n",
    "\n",
    "# # test에 대해서도 동일 처리\n",
    "# for col in cat_cols:\n",
    "#     le = le_dict[col]\n",
    "#     X_test_df[col] = X_test_df[col].map(lambda x: x if x in le.classes_ else None)\n",
    "#     X_test_df[col] = X_test_df[col].fillna(le.classes_[0])\n",
    "#     X_test_df[col] = le.transform(X_test_df[col])\n",
    "# for col in cat_cols:\n",
    "#     le = le_dict[col]\n",
    "#     test[col] = test[col].astype(str).map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
    "# train/validation 분할 (인코딩 후에 실행)\n",
    "\n",
    "X_tr, X_val_split, y_tr, y_val_split = train_test_split(\n",
    "    X_train_df, y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f55c8329-f40a-4730-b4cf-185052516927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feature_names(columns):\n",
    "    import re\n",
    "    cleaned_columns = []\n",
    "    seen = set()\n",
    "    for col in columns:\n",
    "        clean_col = re.sub(r'[^A-Za-z0-9_]+', '_', col)\n",
    "        # 중복 방지 suffix 추가\n",
    "        if clean_col in seen:\n",
    "            i = 1\n",
    "            new_col = f\"{clean_col}_{i}\"\n",
    "            while new_col in seen:\n",
    "                i += 1\n",
    "                new_col = f\"{clean_col}_{i}\"\n",
    "            clean_col = new_col\n",
    "        seen.add(clean_col)\n",
    "        cleaned_columns.append(clean_col)\n",
    "    return cleaned_columns\n",
    "\n",
    "# 적용 예\n",
    "X_train_df.columns = clean_feature_names(X_train_df.columns)\n",
    "X_val.columns = clean_feature_names(X_val.columns)\n",
    "X_test_df.columns = clean_feature_names(X_test_df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf282908-44b5-47d1-a130-a3f1d9d9b102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_df.columns.duplicated().any())  # True면 중복 있음\n",
    "print([col for col in X_train_df.columns if X_train_df.columns.duplicated().any()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58b8185-fa1c-4d3f-93b0-32fe2d402df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # 모델 생성\n",
    "# rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # 탐색할 하이퍼파라미터 그리드\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 150],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "# # GridSearchCV 객체 생성\n",
    "# grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# # GridSearchCV 수행 (학습 데이터 사용)\n",
    "# grid_search.fit(X_train_df, y_train)\n",
    "\n",
    "# # 최적의 하이퍼파라미터 조합\n",
    "# print(f\"최적 하이퍼파라미터: {grid_search.best_params_}\")\n",
    "\n",
    "# # 최고 성능\n",
    "# print(f\"최고 정확도: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b239d-d133-4ebe-9a21-0d1866bf4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Final meta-model predictions:\\n\", final_predictions)\n",
    "\n",
    "# rounded_final_predictions = np.round(final_predictions).astype(int)\n",
    "# submission = pd.DataFrame({\n",
    "#     'target': rounded_final_predictions})\n",
    "\n",
    "# submission.to_csv('submission_lgbm_imeanseo.csv', index=False)\n",
    "# print(\"submission.csv 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e4ba8-f300-4faa-909c-91da5a2d61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred = lgbm.predict(X_test)\n",
    "\n",
    "# 2. 제출 파일용 DataFrame 생성 (샘플 파일이 있다면 그 구조 참고)\n",
    "# 예로 test 데이터에 'id' 컬럼이 있고, 제출 시 'id'와 'target' 컬럼 필요할 경우\n",
    "submission = pd.DataFrame({   \n",
    "    'target': lgbm_pred      # 예측 결과\n",
    "})\n",
    "\n",
    "# 3. 결과 CSV 파일로 저장\n",
    "submission.to_csv('submission_lgbm_imeanseo.csv', index=False)\n",
    "\n",
    "print('submission.csv 파일이 생성되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77887a-9d01-4269-a7d0-1f654266df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_importances = lgbm.feature_importances_\n",
    "lgb_feat = pd.Series(lgb_importances, index=X_train_df.columns).sort_values(ascending=False)\n",
    "print(lgb_feat.tail())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "lgb_feat.head(20).plot(kind='barh')\n",
    "plt.title(\"LightGBM Feature Importances\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34f10957-782a-4371-8033-87aa20f72f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 예측값 반올림 (소수 첫째 자리에서 반올림하고 정수로 변환)\n",
    "rounded_preds = np.round(xgb_pred).astype(int)\n",
    "\n",
    "# 2. 결과를 DataFrame으로 생성\n",
    "submission = pd.DataFrame({\n",
    "    'target': rounded_preds\n",
    "})\n",
    "\n",
    "# 3. CSV 파일로 저장 (인덱스 제외)\n",
    "submission.to_csv('submission_lgbm_imeanseo.csv', index=False)\n",
    "\n",
    "print(\"submission.csv 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e738412a-dfd6-4d45-9a67-cd835aeac784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest OOB Score: 0.8833\n",
      "RandomForest CV RMSE: 18117.3824 (+/- 460.1473)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "# 1. RandomForest 모델 정의 (과적합 방지 + 성능 최적화)\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=400,          # 충분한 트리 개수\n",
    "    max_depth=10,              # 트리 깊이 제한\n",
    "    min_samples_leaf=4,        # 리프 노드 최소 샘플 수\n",
    "    min_samples_split=8,       # 분할을 위한 최소 샘플 수\n",
    "    max_features='sqrt',       # 피처 샘플링 (전체의 제곱근)\n",
    "    bootstrap=True,            # 부트스트랩 샘플링\n",
    "    oob_score=True,           # Out-of-bag 점수 계산\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2. 모델 학습 (RandomForest는 내장된 검증 방식 사용)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 3. Out-of-bag 점수 확인\n",
    "print(f'RandomForest OOB Score: {rf.oob_score_:.4f}')\n",
    "\n",
    "# 4. 교차검증으로 성능 평가\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=kf, \n",
    "                           scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "print(f'RandomForest CV RMSE: {-cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})')\n",
    "\n",
    "# 5. 테스트 예측\n",
    "rf_pred = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1a9b56bf-7ff3-4eb5-9a3e-dd67afb04ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final meta-model predictions:\n",
      " [191767.5303801  324457.67273988 312379.20809751 ...  87342.64613195\n",
      "  74068.06471536  71377.2874585 ]\n",
      "submission.csv 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"Final meta-model predictions:\\n\", final_predictions)\n",
    "\n",
    "rounded_final_predictions = np.round(final_predictions)\n",
    "submission = pd.DataFrame({\n",
    "    'target': final_predictions})\n",
    "\n",
    "submission.to_csv('submission_rf_imeanseo.csv', index=False)\n",
    "print(\"submission.csv 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "482b11d3-88f1-4005-a552-ecae491199f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest 하위 변수:\n",
      " 지하철거리     0.010073\n",
      "회사채금리     0.006301\n",
      "초등학교거리    0.006136\n",
      "delta6    0.003121\n",
      "delta3    0.001710\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델이 학습된 상태여야 합니다.\n",
    "# rf.fit(X_train, y_train) 이 이미 호출된 후에 실행하세요.\n",
    "\n",
    "# 피처 중요도 추출\n",
    "rf_importances = rf.feature_importances_\n",
    "rf_feat = pd.Series(rf_importances, index=X_train_df.columns).sort_values(ascending=False)\n",
    "\n",
    "# 상위 20개 출력\n",
    "print(\"RandomForest 하위 변수:\\n\", rf_feat.tail())\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "rf_feat.head(20).plot(kind='barh')\n",
    "plt.title(\"RandomForest Feature Importances\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de92f44-c1be-4676-98d9-4b6b9abd4899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-10 05:30:30,358] A new study created in memory with name: no-name-4aaea52b-1b2d-4b14-a84f-a1e80e103473\n",
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:33<02:15, 33.94s/it]\u001b[A\n",
      "Model 1 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:07<01:41, 33.97s/it]\u001b[A\n",
      "Model 1 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [01:42<01:08, 34.15s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [02:16<00:34, 34.08s/it]\u001b[A\n",
      "Model 1 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:50<00:00, 34.01s/it]\u001b[A\n",
      "Base models:  33%|██████████████████████████████████████████▎                                                                                    | 1/3 [02:50<05:40, 170.17s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2745\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68673.084757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:09<00:38,  9.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68675.229528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:18<00:28,  9.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68589.420421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:28<00:18,  9.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68682.629430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:37<00:09,  9.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68679.112651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:47<00:00,  9.46s/it]\u001b[A\n",
      "Base models:  67%|█████████████████████████████████████████████████████████████████████████████████████▎                                          | 2/3 [03:37<01:37, 97.90s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:27<01:48, 27.20s/it]\u001b[A\n",
      "Model 3 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:54<01:21, 27.13s/it]\u001b[A\n",
      "Model 3 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [01:21<00:54, 27.23s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [01:48<00:27, 27.17s/it]\u001b[A\n",
      "Model 3 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:15<00:00, 27.06s/it]\u001b[A\n",
      "Base models: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [05:53<00:00, 117.69s/it]\u001b[A\n",
      "[I 2025-09-10 05:36:23,483] Trial 0 finished with value: 7671.356726924271 and parameters: {'rf_n_estimators': 439, 'rf_max_depth': 22, 'rf_min_samples_leaf': 4, 'rf_min_samples_split': 4, 'rf_max_features': 'sqrt', 'lgbm_n_estimators': 870, 'lgbm_max_depth': 18, 'lgbm_learning_rate': 0.01508922761693878, 'lgbm_num_leaves': 80, 'lgbm_subsample': 0.8386528434982617, 'lgbm_colsample_bytree': 0.8066590135363939, 'lgbm_reg_alpha': 0.02597461697983109, 'lgbm_reg_lambda': 0.0014151951292920987, 'xgb_n_estimators': 1015, 'xgb_max_depth': 12, 'xgb_learning_rate': 0.012056019039957636, 'xgb_subsample': 0.706130373338387, 'xgb_colsample_bytree': 0.9899508916648752, 'xgb_gamma': 0.0804206172774185, 'xgb_reg_alpha': 0.0016693469893131411, 'xgb_reg_lambda': 0.006108885284025872}. Best is trial 0 with value: 7671.356726924271.\n",
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:27<01:49, 27.31s/it]\u001b[A\n",
      "Model 1 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:54<01:21, 27.31s/it]\u001b[A\n",
      "Model 1 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [01:21<00:54, 27.24s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [01:48<00:27, 27.16s/it]\u001b[A\n",
      "Model 1 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:15<00:00, 27.13s/it]\u001b[A\n",
      "Base models:  33%|██████████████████████████████████████████▎                                                                                    | 1/3 [02:15<04:31, 135.91s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2745\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68673.084757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:09<00:37,  9.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68675.229528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:18<00:28,  9.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68589.420421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:28<00:19,  9.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68682.629430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:38<00:09,  9.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68679.112651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:47<00:00,  9.52s/it]\u001b[A\n",
      "Base models:  67%|█████████████████████████████████████████████████████████████████████████████████████▎                                          | 2/3 [03:03<01:23, 83.96s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:17<01:11, 17.79s/it]\u001b[A\n",
      "Model 3 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:34<00:52, 17.44s/it]\u001b[A\n",
      "Model 3 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:52<00:35, 17.54s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [01:09<00:17, 17.28s/it]\u001b[A\n",
      "Model 3 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:26<00:00, 17.30s/it]\u001b[A\n",
      "Base models: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [04:30<00:00, 90.12s/it]\u001b[A\n",
      "[I 2025-09-10 05:40:53,949] Trial 1 finished with value: 8404.959074654798 and parameters: {'rf_n_estimators': 413, 'rf_max_depth': 17, 'rf_min_samples_leaf': 4, 'rf_min_samples_split': 8, 'rf_max_features': 'sqrt', 'lgbm_n_estimators': 1267, 'lgbm_max_depth': 12, 'lgbm_learning_rate': 0.01604093780343286, 'lgbm_num_leaves': 37, 'lgbm_subsample': 0.9766687734358311, 'lgbm_colsample_bytree': 0.8754465388571177, 'lgbm_reg_alpha': 0.014771029135041663, 'lgbm_reg_lambda': 0.003581731989947876, 'xgb_n_estimators': 1675, 'xgb_max_depth': 9, 'xgb_learning_rate': 0.01052853421711341, 'xgb_subsample': 0.9894830315714889, 'xgb_colsample_bytree': 0.9386757824151901, 'xgb_gamma': 0.23448250013190045, 'xgb_reg_alpha': 0.2934314196648967, 'xgb_reg_lambda': 0.014227986668123617}. Best is trial 0 with value: 7671.356726924271.\n",
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:38<02:33, 38.43s/it]\u001b[A\n",
      "Model 1 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:17<01:55, 38.57s/it]\u001b[A\n",
      "Model 1 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [01:56<01:17, 38.78s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [02:34<00:38, 38.48s/it]\u001b[A\n",
      "Model 1 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:12<00:00, 38.31s/it]\u001b[A\n",
      "Base models:  33%|██████████████████████████████████████████▎                                                                                    | 1/3 [03:12<06:24, 192.17s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2745\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68673.084757\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:17<01:11, 17.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68675.229528\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:34<00:51, 17.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68589.420421\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:51<00:34, 17.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68682.629430\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [01:08<00:17, 17.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68679.112651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:25<00:00, 17.05s/it]\u001b[A\n",
      "Base models:  67%|████████████████████████████████████████████████████████████████████████████████████▋                                          | 2/3 [04:37<02:09, 129.51s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:37<02:30, 37.73s/it]\u001b[A\n",
      "Model 3 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:15<01:52, 37.57s/it]\u001b[A\n",
      "Model 3 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [01:54<01:16, 38.36s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [02:34<00:38, 38.87s/it]\u001b[A\n",
      "Model 3 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:16<00:00, 40.04s/it]\u001b[A\n",
      "Base models: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [07:54<00:00, 158.03s/it]\u001b[A\n",
      "[I 2025-09-10 05:48:48,151] Trial 2 finished with value: 6997.674570392889 and parameters: {'rf_n_estimators': 455, 'rf_max_depth': 30, 'rf_min_samples_leaf': 3, 'rf_min_samples_split': 8, 'rf_max_features': 'sqrt', 'lgbm_n_estimators': 1855, 'lgbm_max_depth': 9, 'lgbm_learning_rate': 0.04242658540631049, 'lgbm_num_leaves': 91, 'lgbm_subsample': 0.7867698597036263, 'lgbm_colsample_bytree': 0.9318999378912337, 'lgbm_reg_alpha': 0.019420216343485473, 'lgbm_reg_lambda': 0.13534069475281635, 'xgb_n_estimators': 1611, 'xgb_max_depth': 12, 'xgb_learning_rate': 0.019195781111557137, 'xgb_subsample': 0.8962863880270682, 'xgb_colsample_bytree': 0.7210129457635254, 'xgb_gamma': 0.0015825891029491261, 'xgb_reg_alpha': 0.09116690285185983, 'xgb_reg_lambda': 0.021207475414872685}. Best is trial 2 with value: 6997.674570392889.\n",
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:34<02:18, 34.59s/it]\u001b[A\n",
      "Model 1 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:09<01:43, 34.52s/it]\u001b[A\n",
      "Model 1 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [01:43<01:09, 34.62s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [02:18<00:34, 34.58s/it]\u001b[A\n",
      "Model 1 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:54<00:00, 35.22s/it]\u001b[A\n",
      "Base models:  33%|██████████████████████████████████████████▎                                                                                    | 1/3 [02:54<05:49, 174.68s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2745\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68673.084757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:12<00:48, 12.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68675.229528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:24<00:37, 12.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68589.420421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:37<00:24, 12.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68682.629430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:49<00:12, 12.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68679.112651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:01<00:00, 12.31s/it]\u001b[A\n",
      "Base models:  67%|████████████████████████████████████████████████████████████████████████████████████▋                                          | 2/3 [03:56<01:48, 108.17s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:09<00:37,  9.36s/it]\u001b[A\n",
      "Model 3 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:18<00:28,  9.40s/it]\u001b[A\n",
      "Model 3 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:28<00:18,  9.36s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:37<00:09,  9.33s/it]\u001b[A\n",
      "Model 3 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:46<00:00,  9.31s/it]\u001b[A\n",
      "Base models: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [04:42<00:00, 94.31s/it]\u001b[A\n",
      "[I 2025-09-10 05:53:31,251] Trial 3 finished with value: 8021.764494490429 and parameters: {'rf_n_estimators': 435, 'rf_max_depth': 23, 'rf_min_samples_leaf': 2, 'rf_min_samples_split': 9, 'rf_max_features': 'sqrt', 'lgbm_n_estimators': 1216, 'lgbm_max_depth': 12, 'lgbm_learning_rate': 0.011344381572159504, 'lgbm_num_leaves': 70, 'lgbm_subsample': 0.9930610472765987, 'lgbm_colsample_bytree': 0.8655285065516036, 'lgbm_reg_alpha': 0.07649704232222218, 'lgbm_reg_lambda': 0.002104617149706288, 'xgb_n_estimators': 1768, 'xgb_max_depth': 6, 'xgb_learning_rate': 0.04477978452865594, 'xgb_subsample': 0.75614809001778, 'xgb_colsample_bytree': 0.8863472152111841, 'xgb_gamma': 1.2941243561886735, 'xgb_reg_alpha': 0.19035343176275138, 'xgb_reg_lambda': 0.028536716205797976}. Best is trial 2 with value: 6997.674570392889.\n",
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:30<02:01, 30.45s/it]\u001b[A\n",
      "Model 1 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:00<01:31, 30.49s/it]\u001b[A\n",
      "Model 1 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [01:31<01:00, 30.47s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [02:03<00:31, 31.20s/it]\u001b[A\n",
      "Model 1 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:34<00:00, 31.04s/it]\u001b[A\n",
      "Base models:  33%|██████████████████████████████████████████▎                                                                                    | 1/3 [02:34<05:08, 154.48s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2745\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68673.084757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:06<00:25,  6.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68675.229528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:12<00:19,  6.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68589.420421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:19<00:12,  6.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68682.629430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:25<00:06,  6.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68679.112651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:31<00:00,  6.37s/it]\u001b[A\n",
      "Base models:  67%|█████████████████████████████████████████████████████████████████████████████████████▎                                          | 2/3 [03:06<01:22, 82.35s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:40<02:41, 40.32s/it]\u001b[A\n",
      "Model 3 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:20<02:00, 40.13s/it]\u001b[A\n",
      "Model 3 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [02:00<01:20, 40.03s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [02:40<00:39, 39.99s/it]\u001b[A\n",
      "Model 3 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:20<00:00, 39.96s/it]\u001b[A\n",
      "Base models: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [06:26<00:00, 128.80s/it]\u001b[A\n",
      "[I 2025-09-10 05:59:57,832] Trial 4 finished with value: 7220.246061968156 and parameters: {'rf_n_estimators': 611, 'rf_max_depth': 12, 'rf_min_samples_leaf': 5, 'rf_min_samples_split': 10, 'rf_max_features': 'log2', 'lgbm_n_estimators': 892, 'lgbm_max_depth': 16, 'lgbm_learning_rate': 0.039402992504096755, 'lgbm_num_leaves': 35, 'lgbm_subsample': 0.9107924013168762, 'lgbm_colsample_bytree': 0.8393207073715483, 'lgbm_reg_alpha': 0.005000663358621135, 'lgbm_reg_lambda': 0.33255543677791505, 'xgb_n_estimators': 1621, 'xgb_max_depth': 12, 'xgb_learning_rate': 0.014255343581561773, 'xgb_subsample': 0.8688708166250598, 'xgb_colsample_bytree': 0.8125612507743386, 'xgb_gamma': 0.01633545522032646, 'xgb_reg_alpha': 0.008720172737919692, 'xgb_reg_lambda': 0.001933465017838867}. Best is trial 2 with value: 6997.674570392889.\n",
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:39<02:37, 39.42s/it]\u001b[A\n",
      "Model 1 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:19<01:59, 39.74s/it]\u001b[A\n",
      "Model 1 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [01:58<01:19, 39.68s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [02:38<00:39, 39.70s/it]\u001b[A\n",
      "Model 1 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:18<00:00, 39.89s/it]\u001b[A\n",
      "Base models:  33%|██████████████████████████████████████████▎                                                                                    | 1/3 [03:18<06:37, 198.95s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2745\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68673.084757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:16<01:06, 16.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68675.229528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:34<00:52, 17.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68589.420421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:52<00:35, 17.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68682.629430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [01:10<00:17, 17.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68679.112651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:26<00:00, 17.35s/it]\u001b[A\n",
      "Base models:  67%|████████████████████████████████████████████████████████████████████████████████████▋                                          | 2/3 [04:45<02:13, 133.07s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:09<00:39,  9.90s/it]\u001b[A\n",
      "Model 3 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:19<00:28,  9.66s/it]\u001b[A\n",
      "Model 3 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:27<00:18,  9.04s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:35<00:08,  8.74s/it]\u001b[A\n",
      "Model 3 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:44<00:00,  8.58s/it]\u001b[A\n",
      "Base models: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [05:30<00:00, 110.05s/it]\u001b[A\n",
      "[I 2025-09-10 06:05:28,042] Trial 5 finished with value: 7452.150926034207 and parameters: {'rf_n_estimators': 578, 'rf_max_depth': 19, 'rf_min_samples_leaf': 8, 'rf_min_samples_split': 5, 'rf_max_features': 'sqrt', 'lgbm_n_estimators': 1695, 'lgbm_max_depth': 18, 'lgbm_learning_rate': 0.03600226417064865, 'lgbm_num_leaves': 95, 'lgbm_subsample': 0.8896643086725092, 'lgbm_colsample_bytree': 0.9959042127661304, 'lgbm_reg_alpha': 0.06430984507279675, 'lgbm_reg_lambda': 0.11619985702894159, 'xgb_n_estimators': 1527, 'xgb_max_depth': 6, 'xgb_learning_rate': 0.007230391559069124, 'xgb_subsample': 0.9970759930303383, 'xgb_colsample_bytree': 0.8982583085304771, 'xgb_gamma': 0.0027741805106208345, 'xgb_reg_alpha': 0.01806405005599721, 'xgb_reg_lambda': 0.17352239098307334}. Best is trial 2 with value: 6997.674570392889.\n",
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:39<02:38, 39.54s/it]\u001b[A\n",
      "Model 1 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:17<01:56, 38.84s/it]\u001b[A\n",
      "Model 1 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [01:56<01:17, 38.55s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [02:34<00:38, 38.49s/it]\u001b[A\n",
      "Model 1 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:12<00:00, 38.44s/it]\u001b[A\n",
      "Base models:  33%|██████████████████████████████████████████▎                                                                                    | 1/3 [03:12<06:25, 192.93s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2745\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68673.084757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:13<00:53, 13.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68675.229528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:26<00:40, 13.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68589.420421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:40<00:26, 13.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68682.629430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:53<00:13, 13.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68679.112651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:07<00:00, 13.48s/it]\u001b[A\n",
      "Base models:  67%|████████████████████████████████████████████████████████████████████████████████████▋                                          | 2/3 [04:20<01:58, 118.97s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:16<01:06, 16.75s/it]\u001b[A\n",
      "Model 3 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:33<00:50, 16.78s/it]\u001b[A\n",
      "Model 3 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:50<00:33, 16.86s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [01:07<00:17, 17.00s/it]\u001b[A\n",
      "Model 3 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:24<00:00, 16.98s/it]\u001b[A\n",
      "Base models: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [05:44<00:00, 114.94s/it]\u001b[A\n",
      "[I 2025-09-10 06:11:12,900] Trial 6 finished with value: 7988.811725770286 and parameters: {'rf_n_estimators': 784, 'rf_max_depth': 12, 'rf_min_samples_leaf': 2, 'rf_min_samples_split': 6, 'rf_max_features': 'log2', 'lgbm_n_estimators': 1428, 'lgbm_max_depth': 11, 'lgbm_learning_rate': 0.027064600004342056, 'lgbm_num_leaves': 82, 'lgbm_subsample': 0.9643365154324792, 'lgbm_colsample_bytree': 0.8747506631348482, 'lgbm_reg_alpha': 0.6545432771502393, 'lgbm_reg_lambda': 0.0034993883775641843, 'xgb_n_estimators': 1249, 'xgb_max_depth': 10, 'xgb_learning_rate': 0.010282106931476433, 'xgb_subsample': 0.948612921579966, 'xgb_colsample_bytree': 0.8121373474857314, 'xgb_gamma': 0.9866970330248183, 'xgb_reg_alpha': 0.05264264534540749, 'xgb_reg_lambda': 0.08589268878527587}. Best is trial 2 with value: 6997.674570392889.\n",
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:41<02:45, 41.34s/it]\u001b[A\n",
      "Model 1 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:22<02:03, 41.09s/it]\u001b[A\n",
      "Model 1 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [02:00<01:19, 39.77s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [02:38<00:39, 39.12s/it]\u001b[A\n",
      "Model 1 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:21<00:00, 40.45s/it]\u001b[A\n",
      "Base models:  33%|██████████████████████████████████████████▎                                                                                    | 1/3 [03:21<06:42, 201.39s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2745\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68673.084757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:14<00:57, 14.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68675.229528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:28<00:41, 14.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68589.420421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:41<00:27, 13.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68682.629430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:55<00:13, 13.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68679.112651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:09<00:00, 13.71s/it]\u001b[A\n",
      "Base models:  67%|████████████████████████████████████████████████████████████████████████████████████▋                                          | 2/3 [04:30<02:03, 123.52s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:22<01:29, 22.34s/it]\u001b[A\n",
      "Model 3 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:44<01:06, 22.26s/it]\u001b[A\n",
      "Model 3 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [01:07<00:44, 22.40s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [01:28<00:22, 22.18s/it]\u001b[A\n",
      "Model 3 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:50<00:00, 22.03s/it]\u001b[A\n",
      "Base models: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [06:21<00:00, 127.04s/it]\u001b[A\n",
      "[I 2025-09-10 06:17:34,083] Trial 7 finished with value: 7100.652087008652 and parameters: {'rf_n_estimators': 517, 'rf_max_depth': 23, 'rf_min_samples_leaf': 8, 'rf_min_samples_split': 6, 'rf_max_features': 'log2', 'lgbm_n_estimators': 1835, 'lgbm_max_depth': 19, 'lgbm_learning_rate': 0.047328904667502, 'lgbm_num_leaves': 52, 'lgbm_subsample': 0.864408411579974, 'lgbm_colsample_bytree': 0.9131724160229813, 'lgbm_reg_alpha': 0.5034584649726582, 'lgbm_reg_lambda': 0.6365606405751175, 'xgb_n_estimators': 1267, 'xgb_max_depth': 11, 'xgb_learning_rate': 0.02695274134522273, 'xgb_subsample': 0.8018671875796505, 'xgb_colsample_bytree': 0.8577912796974524, 'xgb_gamma': 3.239834846438071, 'xgb_reg_alpha': 0.005786777816348559, 'xgb_reg_lambda': 0.0013424562024809078}. Best is trial 2 with value: 6997.674570392889.\n",
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:43<02:55, 43.93s/it]\u001b[A\n",
      "Model 1 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:27<02:10, 43.56s/it]\u001b[A\n",
      "Model 1 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [02:10<01:26, 43.29s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [02:53<00:43, 43.19s/it]\u001b[A\n",
      "Model 1 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:36<00:00, 43.31s/it]\u001b[A\n",
      "Base models:  33%|██████████████████████████████████████████▎                                                                                    | 1/3 [03:36<07:13, 216.76s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2745\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68673.084757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:12<00:48, 12.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68675.229528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:24<00:36, 12.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68589.420421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:36<00:24, 12.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68682.629430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:48<00:12, 12.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68679.112651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:00<00:00, 12.08s/it]\u001b[A\n",
      "Base models:  67%|████████████████████████████████████████████████████████████████████████████████████▋                                          | 2/3 [04:37<02:04, 124.81s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:13<00:54, 13.51s/it]\u001b[A\n",
      "Model 3 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:27<00:40, 13.57s/it]\u001b[A\n",
      "Model 3 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:40<00:27, 13.61s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:54<00:13, 13.67s/it]\u001b[A\n",
      "Model 3 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:09<00:00, 14.31s/it]\u001b[A\n",
      "Base models: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [05:47<00:00, 115.73s/it]\u001b[A\n",
      "[I 2025-09-10 06:23:21,450] Trial 8 finished with value: 7351.845333125864 and parameters: {'rf_n_estimators': 551, 'rf_max_depth': 23, 'rf_min_samples_leaf': 4, 'rf_min_samples_split': 4, 'rf_max_features': 'log2', 'lgbm_n_estimators': 1120, 'lgbm_max_depth': 20, 'lgbm_learning_rate': 0.012864839049526266, 'lgbm_num_leaves': 79, 'lgbm_subsample': 0.8501168179736418, 'lgbm_colsample_bytree': 0.8307419968424867, 'lgbm_reg_alpha': 0.11340838353190849, 'lgbm_reg_lambda': 0.18061164246298073, 'xgb_n_estimators': 1788, 'xgb_max_depth': 8, 'xgb_learning_rate': 0.030639034574301408, 'xgb_subsample': 0.8834505288112685, 'xgb_colsample_bytree': 0.7074313527871058, 'xgb_gamma': 0.040060365648101656, 'xgb_reg_alpha': 0.003925110463921339, 'xgb_reg_lambda': 0.0768921917710027}. Best is trial 2 with value: 6997.674570392889.\n",
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:49<03:19, 49.84s/it]\u001b[A\n",
      "Model 1 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:40<02:30, 50.20s/it]\u001b[A\n",
      "Model 1 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [02:30<01:40, 50.03s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [03:15<00:48, 48.32s/it]\u001b[A\n",
      "Model 1 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:59<00:00, 46.67s/it]\u001b[A\n",
      "Base models:  33%|██████████████████████████████████████████▎                                                                                    | 1/3 [03:59<07:59, 239.56s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2745\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68673.084757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:08<00:34,  8.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68675.229528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:16<00:24,  8.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68589.420421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:24<00:16,  8.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68682.629430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:33<00:08,  8.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68679.112651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:41<00:00,  8.32s/it]\u001b[A\n",
      "Base models:  67%|████████████████████████████████████████████████████████████████████████████████████▋                                          | 2/3 [04:41<02:03, 123.12s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:08<00:32,  8.19s/it]\u001b[A\n",
      "Model 3 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:16<00:24,  8.11s/it]\u001b[A\n",
      "Model 3 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:24<00:16,  8.13s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:32<00:08,  8.18s/it]\u001b[A\n",
      "Model 3 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:40<00:00,  8.21s/it]\u001b[A\n",
      "Base models: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [05:22<00:00, 107.37s/it]\u001b[A\n",
      "[I 2025-09-10 06:28:43,608] Trial 9 finished with value: 8390.492589074243 and parameters: {'rf_n_estimators': 778, 'rf_max_depth': 14, 'rf_min_samples_leaf': 5, 'rf_min_samples_split': 9, 'rf_max_features': 'sqrt', 'lgbm_n_estimators': 951, 'lgbm_max_depth': 18, 'lgbm_learning_rate': 0.04614942328183108, 'lgbm_num_leaves': 67, 'lgbm_subsample': 0.7373824936746135, 'lgbm_colsample_bytree': 0.7290157038413482, 'lgbm_reg_alpha': 0.0050490413334705105, 'lgbm_reg_lambda': 0.13533449269864312, 'xgb_n_estimators': 1271, 'xgb_max_depth': 7, 'xgb_learning_rate': 0.02390979244219748, 'xgb_subsample': 0.7875814595831765, 'xgb_colsample_bytree': 0.8833214385477384, 'xgb_gamma': 4.825129949348402, 'xgb_reg_alpha': 0.08021739050359561, 'xgb_reg_lambda': 0.0814157092299884}. Best is trial 2 with value: 6997.674570392889.\n",
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# 1. train, test 데이터 준비 (이미 준비된 DataFrame 가정)\n",
    "# train: 학습용 데이터 (X_train, y_train 분리 필요)\n",
    "# test: 테스트 데이터 (예측만 수행)\n",
    "\n",
    "# # 2. 기본 모델 정의 (튜닝된 파라미터로 변경 가능)\n",
    "# # RandomForestRegressor with overfitting control\n",
    "# # rf = RandomForestRegressor(\n",
    "# #     n_estimators=600,          # 트리 개수, 많을수록 안정\n",
    "# #     max_depth=15,              # 트리 깊이 제한\n",
    "# #     min_samples_leaf=4,        # 최소 잎노드 샘플 수\n",
    "# #     min_samples_split=8,       # 내부 노드를 분할하는 최소 샘플 수\n",
    "# #     max_features='sqrt',       # 최대 피처 샘플링 비율\n",
    "# #     random_state=42,\n",
    "# #     n_jobs=-1\n",
    "# # )\n",
    "\n",
    "# # LightGBM with regularization and early stopping\n",
    "# # lgbm = LGBMRegressor(\n",
    "# #     n_estimators=1000,\n",
    "# #     max_depth=12,\n",
    "# #     learning_rate=0.02,\n",
    "# #     num_leaves=70,\n",
    "# #     subsample=0.8,                 # 데이터 샘플링 비율\n",
    "# #     subsample_freq=1,             # 샘플링 빈도\n",
    "# #     colsample_bytree=0.8,         # 피처 샘플링 비율\n",
    "# #     reg_alpha=0.2,                # L1 규제\n",
    "# #     reg_lambda=0.3,               # L2 규제\n",
    "# #     random_state=42,\n",
    "# #     n_jobs=-1\n",
    "# # )\n",
    "# rf = RandomForestRegressor(\n",
    "#     n_estimators=600,        # 트리 수 증가로 안정성 향상\n",
    "#     max_depth=15,            # 깊이 조금 더 키움\n",
    "#     min_samples_leaf=3,\n",
    "#     min_samples_split=5,\n",
    "#     max_features='sqrt',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# lgbm = LGBMRegressor(\n",
    "#     n_estimators=1500,       # 학습 횟수 증가\n",
    "#     max_depth=12,\n",
    "#     learning_rate=0.02,      # 학습률 감소로 안정성 증가\n",
    "#     num_leaves=70,           # 잎사귀 수 증가\n",
    "#     subsample=0.9,\n",
    "#     subsample_freq=1,\n",
    "#     colsample_bytree=0.85,\n",
    "#     reg_alpha=0.25,\n",
    "#     reg_lambda=0.4,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# xgb = XGBRegressor(\n",
    "#     n_estimators=1500,\n",
    "#     max_depth=9,\n",
    "#     learning_rate=0.02,\n",
    "#     subsample=0.85,\n",
    "#     colsample_bytree=0.85,\n",
    "#     gamma=0.5,\n",
    "#     reg_alpha=0.2,\n",
    "#     reg_lambda=0.6,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     verbosity=0\n",
    "# )\n",
    "\n",
    "# # # XGBoost with regularization and early stopping\n",
    "# # xgb = XGBRegressor(\n",
    "# #     n_estimators=1500,\n",
    "# #     max_depth=9,\n",
    "# #     learning_rate=0.02,\n",
    "# #     subsample=0.8,\n",
    "# #     colsample_bytree=0.8,\n",
    "# #     gamma=1,                     # 리프 노드 분할 최소 손실 감소량\n",
    "# #     reg_alpha=0.15,              # L1 규제\n",
    "# #     reg_lambda=0.5,              # L2 규제\n",
    "# #     random_state=42,\n",
    "# #     n_jobs=-1\n",
    "# # )\n",
    "\n",
    "# 6. 메타 피처 생성에 tqdm 추가\n",
    "def create_meta_features(models, X, y, kf):\n",
    "    n_samples = X.shape[0]\n",
    "    n_models  = len(models)\n",
    "    meta_features = np.zeros((n_samples, n_models))\n",
    "\n",
    "    # 모델별 진행바\n",
    "    for i, model in enumerate(tqdm(models, desc=\"Base models\")):\n",
    "        temp_pred = np.zeros(n_samples)\n",
    "        # fold별 진행바\n",
    "        for train_idx, val_idx in tqdm(kf.split(X), total=kf.get_n_splits(), desc=f\"Model {i+1} folds\", leave=False):\n",
    "            X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_tr = y[train_idx]\n",
    "        # desc=f\"Model {i+1} folds\",\n",
    "         # leave=False)\n",
    "            y_tr = y[train_idx]\n",
    "            if isinstance(model, LGBMRegressor):\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y[val_idx])],\n",
    "                    eval_metric='rmse',\n",
    "                    callbacks=[early_stopping(stopping_rounds=50, verbose=False)]\n",
    "                )\n",
    "            else:\n",
    "                model.fit(X_tr, y_tr)\n",
    "            temp_pred[val_idx] = model.predict(X_val)\n",
    "        meta_features[:, i] = temp_pred\n",
    "\n",
    "    return meta_features\n",
    "\n",
    "# 7. 테스트 메타 피처 생성에 tqdm 추가\n",
    "def get_test_meta_features(models, X_train, y_train, X_test):\n",
    "    n_samples = X_test.shape[0]\n",
    "    n_models  = len(models)\n",
    "    meta_test_features = np.zeros((n_samples, n_models))\n",
    "\n",
    "    # 모델별 진행바\n",
    "    for i, model in enumerate(tqdm(models, desc=\"Retrain & Predict\")):\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        meta_test_features[:, i] = preds\n",
    "\n",
    "    return meta_test_features\n",
    "\n",
    "def objective(trial):\n",
    "    # 기본 모델 하이퍼파라미터를 trial.suggest_... 로 동적으로 탐색\n",
    "    rf_params = {\n",
    "        'n_estimators': trial.suggest_int(\"rf_n_estimators\", 300, 800),\n",
    "        'max_depth': trial.suggest_int(\"rf_max_depth\", 10, 30),\n",
    "        'min_samples_leaf': trial.suggest_int(\"rf_min_samples_leaf\", 1, 8),\n",
    "        'min_samples_split': trial.suggest_int(\"rf_min_samples_split\", 2, 10),\n",
    "        'max_features': trial.suggest_categorical(\"rf_max_features\", [\"sqrt\", \"log2\"]),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    lgbm_params = {\n",
    "        'n_estimators': trial.suggest_int(\"lgbm_n_estimators\", 800, 2000),\n",
    "        'max_depth': trial.suggest_int(\"lgbm_max_depth\", 8, 20),\n",
    "        'learning_rate': trial.suggest_loguniform(\"lgbm_learning_rate\", 0.005, 0.05),\n",
    "        'num_leaves': trial.suggest_int(\"lgbm_num_leaves\", 30, 100),\n",
    "        'subsample': trial.suggest_uniform(\"lgbm_subsample\", 0.7, 1.0),          \n",
    "        'colsample_bytree': trial.suggest_uniform(\"lgbm_colsample_bytree\", 0.7, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform(\"lgbm_reg_alpha\", 1e-3, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform(\"lgbm_reg_lambda\", 1e-3, 1.0),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "        \n",
    "    xgb_params = {\n",
    "        'n_estimators': trial.suggest_int(\"xgb_n_estimators\", 800, 2000),\n",
    "        'max_depth': trial.suggest_int(\"xgb_max_depth\", 6, 12),\n",
    "        'learning_rate': trial.suggest_loguniform(\"xgb_learning_rate\", 0.005, 0.05),\n",
    "        'subsample': trial.suggest_uniform(\"xgb_subsample\", 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform(\"xgb_colsample_bytree\", 0.7, 1.0),\n",
    "        'gamma': trial.suggest_loguniform(\"xgb_gamma\", 1e-3, 10),\n",
    "        'reg_alpha': trial.suggest_loguniform(\"xgb_reg_alpha\", 1e-3, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform(\"xgb_reg_lambda\", 1e-3, 1.0),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    # 모델 생성에 하이퍼파라미터를 동적 적용\n",
    "    rf_model = RandomForestRegressor(**rf_params)\n",
    "    lgbm_model = LGBMRegressor(**lgbm_params)\n",
    "    xgb_model = XGBRegressor(**xgb_params)\n",
    "    models = [rf_model, lgbm_model, xgb_model]\n",
    "\n",
    "    # 3. KFold 설정: 데이터셋을 5개 fold로 분할, 랜덤 셔플 후 고정 시드로 재현성 보장\n",
    "    kf_inner = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    meta_X_train = create_meta_features(models, X_train, y_train, kf_inner)\n",
    "\n",
    "    meta_model = Ridge(alpha=1.0, random_state=42)\n",
    "    meta_model.fit(meta_X_train, y_train)\n",
    "    train_preds = meta_model.predict(meta_X_train)\n",
    "    rmse = mean_squared_error(y_train, train_preds, squared=False)\n",
    "    return rmse\n",
    "\n",
    "# 4. Optuna 스터디 실행\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials= 30)\n",
    "\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "# 5. 최적 하이퍼파라미터로 메타 피처 생성 및 최종 예측 (선택적)\n",
    "best_params = study.best_params\n",
    "\n",
    "# RF, LGBM, XGB 하이퍼파라미터 재구성\n",
    "rf_best = RandomForestRegressor(\n",
    "    n_estimators=best_params[\"rf_n_estimators\"],\n",
    "    max_depth=best_params[\"rf_max_depth\"],\n",
    "    min_samples_leaf=best_params[\"rf_min_samples_leaf\"],\n",
    "    min_samples_split=best_params[\"rf_min_samples_split\"],\n",
    "    max_features=best_params[\"rf_max_features\"],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lgbm_best = LGBMRegressor(\n",
    "    n_estimators=best_params[\"lgbm_n_estimators\"],\n",
    "    max_depth=best_params[\"lgbm_max_depth\"],\n",
    "    learning_rate=best_params[\"lgbm_learning_rate\"],\n",
    "    num_leaves=best_params[\"lgbm_num_leaves\"],\n",
    "    subsample=best_params[\"lgbm_subsample\"],\n",
    "    colsample_bytree=best_params[\"lgbm_colsample_bytree\"],\n",
    "    reg_alpha=best_params[\"lgbm_reg_alpha\"],\n",
    "    reg_lambda=best_params[\"lgbm_reg_lambda\"],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_best = XGBRegressor(\n",
    "    n_estimators=best_params[\"xgb_n_estimators\"],\n",
    "    max_depth=best_params[\"xgb_max_depth\"],\n",
    "    learning_rate=best_params[\"xgb_learning_rate\"],\n",
    "    subsample=best_params[\"xgb_subsample\"],\n",
    "    colsample_bytree=best_params[\"xgb_colsample_bytree\"],\n",
    "    gamma=best_params[\"xgb_gamma\"],\n",
    "    reg_alpha=best_params[\"xgb_reg_alpha\"],\n",
    "    reg_lambda=best_params[\"xgb_reg_lambda\"],\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "models_best = [rf_best, lgbm_best, xgb_best]\n",
    "\n",
    "# meta_X_train_best = create_meta_features(models_best, X_train, y_train, kf_inner)\n",
    "# meta_model = Ridge(alpha=1.0, random_state=42)\n",
    "# meta_model.fit(meta_X_train_best, y_train)\n",
    "# meta_X_test_best = get_test_meta_features(models_best, X_train, y_train, X_test)\n",
    "# final_predictions = meta_model.predict(meta_X_test_best)\n",
    "\n",
    "rmse_train = mean_squared_error(y_train, train_preds, squared=False)\n",
    "print(f\"학습 데이터 RMSE (원래 스케일): {rmse_train:.4f}\")\n",
    "\n",
    "# 메타 피처 생성 및 학습\n",
    "meta_X_train_best = create_meta_features(models_best, X_train, y_train_log, kf_inner)\n",
    "meta_model = Ridge(alpha=1.0, random_state=42)\n",
    "meta_model.fit(meta_X_train_best, y_train_log)\n",
    "\n",
    "# 테스트 데이터 예측 (로그 스케일)\n",
    "meta_X_test_best = get_test_meta_features(models_best, X_train, y_train_log, X_test)\n",
    "final_predictions_log = meta_model.predict(meta_X_test_best)\n",
    "\n",
    "rounded_preds = np.round(final_predictions).astype(int)\n",
    "submission = pd.DataFrame({'target': rounded_preds})\n",
    "submission.to_csv('submission_optuna_3.csv', index=False)\n",
    "\n",
    "print(\"submission.csv 파일이 생성되었습니다.\")\n",
    "\n",
    "# Trial 4 finished with value: 6976.950134385912 and parameters: \n",
    "# {'rf_n_estimators': 416, 'rf_max_depth': 29, 'rf_min_samples_leaf': 7, 'rf_min_samples_split': 10, 'rf_max_features': 'log2', 'lgbm_n_estimators': 1702, 'lgbm_max_depth': 12, 'lgbm_learning_rate': 0.03250541539651261, 'lgbm_num_leaves': 100, 'lgbm_subsample': 0.8825134881070337, 'lgbm_colsample_bytree': 0.7694061527956504, 'lgbm_reg_alpha': 0.0018934229948617048, 'lgbm_reg_lambda': 0.013487380991073253, 'xgb_n_estimators': 1859, 'xgb_max_depth': 11, 'xgb_learning_rate': 0.027347549729385235, 'xgb_subsample': 0.9874638592404601, 'xgb_colsample_bytree': 0.8254732898196115, 'xgb_gamma': 2.0678529807138832, 'xgb_reg_alpha': 0.9573441222792469, 'xgb_reg_lambda': 0.002039999771783618}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6061377-b56b-456f-b200-5b20668b51e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base models:   0%|                                                                                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:33<02:12, 33.14s/it]\u001b[A\n",
      "Model 1 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [01:06<01:39, 33.22s/it]\u001b[A\n",
      "Model 1 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [01:39<01:06, 33.18s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [02:12<00:33, 33.25s/it]\u001b[A\n",
      "Model 1 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:46<00:00, 33.40s/it]\u001b[A\n",
      "Base models:  33%|██████████████████████████████████████████▎                                                                                    | 1/3 [02:46<05:33, 166.57s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3255\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 10.929048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:18<01:14, 18.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3258\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 10.928988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:37<00:55, 18.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3258\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 10.928201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:55<00:37, 18.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3258\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 10.928739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [01:14<00:18, 18.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3258\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 10.929101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:32<00:00, 18.38s/it]\u001b[A\n",
      "Base models:  67%|████████████████████████████████████████████████████████████████████████████████████▋                                          | 2/3 [04:18<02:02, 122.89s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|█████████████████████████▏                                                                                                    | 1/5 [00:06<00:25,  6.29s/it]\u001b[A\n",
      "Model 3 folds:  40%|██████████████████████████████████████████████████▍                                                                           | 2/5 [00:12<00:18,  6.19s/it]\u001b[A\n",
      "Model 3 folds:  60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 3/5 [00:18<00:12,  6.23s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 4/5 [00:24<00:06,  6.25s/it]\u001b[A\n",
      "Model 3 folds: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:31<00:00,  6.21s/it]\u001b[A\n",
      "Base models: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [04:50<00:00, 96.67s/it]\u001b[A\n",
      "Retrain & Predict:  33%|████████████████████████████████████████▋                                                                                 | 1/3 [00:41<01:22, 41.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3258\n",
      "[LightGBM] [Info] Number of data points in the train set: 635467, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 10.928815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain & Predict: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:08<00:00, 22.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_optuna_2.csv 파일이 생성되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf_best = RandomForestRegressor(\n",
    "    n_estimators=416,\n",
    "    max_depth=29,\n",
    "    min_samples_leaf=7,\n",
    "    min_samples_split=10,\n",
    "    max_features='log2',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm_best = LGBMRegressor(\n",
    "    n_estimators=1702,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.03250541539651261,\n",
    "    num_leaves=100,\n",
    "    subsample=0.8825134881070337,\n",
    "    colsample_bytree=0.7694061527956504,\n",
    "    reg_alpha=0.0018934229948617048,\n",
    "    reg_lambda=0.013487380991073253,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_best = XGBRegressor(\n",
    "    n_estimators=1859,\n",
    "    max_depth=11,\n",
    "    learning_rate=0.027347549729385235,\n",
    "    subsample=0.9874638592404601,\n",
    "    colsample_bytree=0.8254732898196115,\n",
    "    gamma=2.0678529807138832,\n",
    "    reg_alpha=0.9573441222792469,\n",
    "    reg_lambda=0.002039999771783618,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "models_best = [rf_best, lgbm_best, xgb_best]\n",
    "\n",
    "kf_inner = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. 메타 피처 생성 (train셋에 대해서)\n",
    "meta_X_train_best = create_meta_features(models_best, X_train, y_train_log, kf_inner)\n",
    "\n",
    "# 4. 메타 모델 학습 (Ridge 등 사용)\n",
    "from sklearn.linear_model import Ridge\n",
    "meta_model = Ridge(alpha=1.0, random_state=42)\n",
    "meta_model.fit(meta_X_train_best, y_train_log)\n",
    "\n",
    "# 5. 테스트 데이터 메타 피처 생성\n",
    "meta_X_test_best = get_test_meta_features(models_best, X_train, y_train_log, X_test)\n",
    "\n",
    "# 6. 테스트 예측 (로그 스케일)\n",
    "final_predictions_log = meta_model.predict(meta_X_test_best)\n",
    "\n",
    "# 7. 로그 역변환 및 제출용 반올림\n",
    "import numpy as np\n",
    "final_predictions = np.exp(final_predictions_log)\n",
    "rounded_preds = np.round(final_predictions).astype(int)\n",
    "\n",
    "# 8. 제출 파일 생성\n",
    "import pandas as pd\n",
    "submission = pd.DataFrame({'target': rounded_preds})\n",
    "submission.to_csv('submission_optuna_2.csv', index=False)\n",
    "\n",
    "print(\"submission_optuna_2.csv 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad54b03c-01da-44e0-b4ac-69974eedbfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE (원본 스케일): 7599.7428\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 메타 모델 학습 완료 후 train 예측값 생성\n",
    "train_preds_log = meta_model.predict(meta_X_train_best)\n",
    "\n",
    "# 로그 스케일에서 역변환\n",
    "train_preds = np.expm1(train_preds_log)  # np.expm1는 exp(x)-1 함수\n",
    "\n",
    "# 실제 타겟 원본 스케일 (y_train)과 비교해 RMSE 계산\n",
    "rmse_train = mean_squared_error(y_train, train_preds, squared=False)\n",
    "\n",
    "print(f\"Train RMSE (원본 스케일): {rmse_train:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "852de645-173c-41a6-a626-abda041d7f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base models:   0%|                                                                                          | 0/3 [00:00<?, ?it/s]\n",
      "Model 1 folds:   0%|                                                                                        | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 1 folds:  20%|████████████████                                                                | 1/5 [00:25<01:40, 25.15s/it]\u001b[A\n",
      "Model 1 folds:  40%|████████████████████████████████                                                | 2/5 [00:50<01:16, 25.41s/it]\u001b[A\n",
      "Model 1 folds:  60%|████████████████████████████████████████████████                                | 3/5 [01:16<00:50, 25.48s/it]\u001b[A\n",
      "Model 1 folds:  80%|████████████████████████████████████████████████████████████████                | 4/5 [01:41<00:25, 25.42s/it]\u001b[A\n",
      "Model 1 folds: 100%|████████████████████████████████████████████████████████████████████████████████| 5/5 [02:07<00:00, 25.47s/it]\u001b[A\n",
      "Base models:  33%|███████████████████████████                                                      | 1/3 [02:07<04:14, 127.19s/it]\u001b[A\n",
      "Model 2 folds:   0%|                                                                                        | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2382\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 10.929048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  20%|████████████████                                                                | 1/5 [00:07<00:30,  7.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 508373, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 10.928988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  40%|████████████████████████████████                                                | 2/5 [00:15<00:22,  7.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 10.928201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  60%|████████████████████████████████████████████████                                | 3/5 [00:23<00:15,  7.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 10.928739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds:  80%|████████████████████████████████████████████████████████████████                | 4/5 [00:31<00:07,  7.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 508374, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 10.929101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 folds: 100%|████████████████████████████████████████████████████████████████████████████████| 5/5 [00:38<00:00,  7.82s/it]\u001b[A\n",
      "Base models:  67%|██████████████████████████████████████████████████████▋                           | 2/3 [02:46<01:15, 75.26s/it]\u001b[A\n",
      "Model 3 folds:   0%|                                                                                        | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Model 3 folds:  20%|████████████████                                                                | 1/5 [00:05<00:20,  5.12s/it]\u001b[A\n",
      "Model 3 folds:  40%|████████████████████████████████                                                | 2/5 [00:10<00:15,  5.13s/it]\u001b[A\n",
      "Model 3 folds:  60%|████████████████████████████████████████████████                                | 3/5 [00:15<00:10,  5.15s/it]\u001b[A\n",
      "Model 3 folds:  80%|████████████████████████████████████████████████████████████████                | 4/5 [00:20<00:05,  5.27s/it]\u001b[A\n",
      "Model 3 folds: 100%|████████████████████████████████████████████████████████████████████████████████| 5/5 [00:25<00:00,  5.21s/it]\u001b[A\n",
      "Base models: 100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [03:12<00:00, 64.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 RMSE (원래 스케일): 8778.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain & Predict:  33%|█████████████████████████▎                                                  | 1/3 [00:31<01:03, 31.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 635467, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 10.928815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain & Predict: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [00:45<00:00, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv 파일이 생성되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 베스트 하이퍼파라미터로 모델 생성\n",
    "rf_best = RandomForestRegressor(\n",
    "    n_estimators=527,\n",
    "    max_depth=11,\n",
    "    min_samples_leaf=8,\n",
    "    min_samples_split=9,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm_best = LGBMRegressor(\n",
    "    n_estimators=801,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.04106361615104415,\n",
    "    num_leaves=92,\n",
    "    # subsample 필드는 탐색 안 해서 기본값 1.0 유지\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=1.0,  # Optuna 결과에 없으면 기본값 사용\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_best = XGBRegressor(\n",
    "    n_estimators=1880,\n",
    "    max_depth=11,\n",
    "    learning_rate=0.03714747220843659,\n",
    "    subsample=0.9262954478976996,\n",
    "    colsample_bytree=0.7112897029011118,\n",
    "    gamma=0.7723753348363707,\n",
    "    reg_alpha=0.12643220684416703,\n",
    "    reg_lambda=0.942169270895758,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "models_best = [rf_best, lgbm_best, xgb_best]\n",
    "\n",
    "# KFold 정의 (필요 시)\n",
    "kf_inner = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 1. 로그 변환된 타깃\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "# 2. 메타 피처 생성 및 메타 모델 학습\n",
    "meta_X_train_best = create_meta_features(models_best, X_train, y_train_log, kf_inner)\n",
    "meta_model = Ridge(alpha=1.0, random_state=42)\n",
    "meta_model.fit(meta_X_train_best, y_train_log)\n",
    "\n",
    "# 3. 학습 데이터에 대한 로그 스케일 예측\n",
    "train_preds_log = meta_model.predict(meta_X_train_best)\n",
    "\n",
    "# 4. 역변환(원래 스케일)\n",
    "train_preds = np.expm1(train_preds_log)\n",
    "\n",
    "# 5. 원래 스케일의 실제값과 예측값으로 RMSE 계산\n",
    "rmse_train = mean_squared_error(y_train, train_preds, squared=False)\n",
    "print(f\"학습 데이터 RMSE (원래 스케일): {rmse_train:.4f}\")\n",
    "\n",
    "# 6. 테스트 데이터 메타 피처 생성 및 예측\n",
    "meta_X_test_best = get_test_meta_features(models_best, X_train, y_train_log, X_test)\n",
    "final_predictions_log = meta_model.predict(meta_X_test_best)\n",
    "\n",
    "# 7. 역변환 후 제출용 예측값 생성\n",
    "final_predictions = np.expm1(final_predictions_log)\n",
    "\n",
    "# 필요시 반올림 등 후처리 해 제출 파일 생성\n",
    "# 8. 반올림 및 CSV 파일 생성 (필요 시)\n",
    "rounded_preds = np.round(final_predictions).astype(int)\n",
    "submission = pd.DataFrame({'target': rounded_preds})\n",
    "submission.to_csv('submission_optuna_log.csv', index=False)\n",
    "\n",
    "print(\"submission.csv 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d3f4e-71e7-43f0-ba7c-9370ef70f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Count Encoding (데이터 전처리)\n",
    "# for col in ['구', '아파트명']:\n",
    "#     if col in X_train.columns:  # 컬럼 존재 확인\n",
    "#         freq_map = X_train[col].value_counts().to_dict()\n",
    "#         X_train[col + '_count'] = X_train[col].map(freq_map)\n",
    "#         X_test[col + '_count'] = X_test[col].map(freq_map).fillna(0)\n",
    "        \n",
    "#         # 원본 범주형 컬럼 제거\n",
    "#         X_train = X_train.drop(columns=[col])\n",
    "#         X_test = X_test.drop(columns=[col])\n",
    "\n",
    "\n",
    "# # 2. 타겟 이상치 클리핑 함수 및 적용\n",
    "# def clip_outliers(arr):\n",
    "#     q1 = np.quantile(arr, 0.25)\n",
    "#     q3 = np.quantile(arr, 0.75)\n",
    "#     iqr = q3 - q1\n",
    "#     lower = q1 - 1.5 * iqr\n",
    "#     upper = q3 + 1.5 * iqr\n",
    "#     return np.clip(arr, lower, upper)\n",
    "\n",
    "# y_train = clip_outliers(y_train)\n",
    "\n",
    "# # 3. 계약년월 기준 정렬\n",
    "# X_train = X_train.sort_values('계약년월')\n",
    "# y_train = y_train[X_train.index]\n",
    "\n",
    "# 4. 로그 변환\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "# 5. 메타 피처 생성 함수 정의\n",
    "def create_meta_features(models, X, y, kf):\n",
    "    n_samples = len(X)\n",
    "    n_models = len(models)\n",
    "    meta_features = np.zeros((n_samples, n_models), dtype=float)\n",
    "    \n",
    "    for i, model in enumerate(tqdm(models, desc=\"Base models\")):\n",
    "        temp_pred = np.zeros(n_samples)\n",
    "        for train_idx, val_idx in tqdm(kf.split(X), total=kf.get_n_splits(), desc=f\"Model {i+1} folds\", leave=False):\n",
    "            X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_tr = y[train_idx]\n",
    "            \n",
    "            if isinstance(model, LGBMRegressor):\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y[val_idx])],\n",
    "                    eval_metric='rmse',\n",
    "                    callbacks=[early_stopping(stopping_rounds=50, verbose=False)]\n",
    "                )\n",
    "            else:\n",
    "                model.fit(X_tr, y_tr)\n",
    "            \n",
    "            temp_pred[val_idx] = model.predict(X_val)\n",
    "        meta_features[:, i] = temp_pred\n",
    "    return meta_features\n",
    "\n",
    "# 6. 테스트 메타 피처 생성 함수 정의\n",
    "def get_test_meta_features(models, X_train, y_train, X_test):\n",
    "    n_samples = X_test.shape[0]\n",
    "    n_models = len(models)\n",
    "    meta_test_features = np.zeros((n_samples, n_models), dtype=float)\n",
    "    \n",
    "    for i, model in enumerate(tqdm(models, desc=\"Retrain & Predict\")):\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        meta_test_features[:, i] = preds\n",
    "    return meta_test_features\n",
    "\n",
    "# 7. Optuna objective 함수 정의\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 탐색 범위\n",
    "    # rf_params = {\n",
    "    #     'n_estimators': trial.suggest_int(\"rf_n_estimators\", 300, 800),\n",
    "    #     'max_depth': trial.suggest_int(\"rf_max_depth\", 10, 40),\n",
    "    #     'min_samples_leaf': trial.suggest_int(\"rf_min_samples_leaf\", 1, 8),\n",
    "    #     'min_samples_split': trial.suggest_int(\"rf_min_samples_split\", 2, 20),\n",
    "    #     'max_features': trial.suggest_categorical(\"rf_max_features\", [\"sqrt\", \"log2\", None]),\n",
    "    #     'random_state': 42,\n",
    "    #     'n_jobs': -1\n",
    "    # }\n",
    "    \n",
    "    lgbm_params = {\n",
    "        'n_estimators': trial.suggest_int(\"lgbm_n_estimators\", 800, 3000),\n",
    "        'max_depth': trial.suggest_int(\"lgbm_max_depth\", 8, 25),\n",
    "        'learning_rate': trial.suggest_loguniform(\"lgbm_learning_rate\", 0.001, 0.1),\n",
    "        'num_leaves': trial.suggest_int(\"lgbm_num_leaves\", 30, 150),\n",
    "        'subsample': trial.suggest_uniform(\"lgbm_subsample\", 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform(\"lgbm_colsample_bytree\", 0.7, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform(\"lgbm_reg_alpha\", 1e-5, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform(\"lgbm_reg_lambda\", 1e-5, 1.0),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    xgb_params = {\n",
    "        'n_estimators': trial.suggest_int(\"xgb_n_estimators\", 800, 3000),\n",
    "        'max_depth': trial.suggest_int(\"xgb_max_depth\", 4, 15),\n",
    "        'learning_rate': trial.suggest_loguniform(\"xgb_learning_rate\", 0.001, 0.1),\n",
    "        'subsample': trial.suggest_uniform(\"xgb_subsample\", 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform(\"xgb_colsample_bytree\", 0.7, 1.0),\n",
    "        'gamma': trial.suggest_loguniform(\"xgb_gamma\", 1e-5, 50),\n",
    "        'reg_alpha': trial.suggest_loguniform(\"xgb_reg_alpha\", 1e-5, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform(\"xgb_reg_lambda\", 1e-5, 1.0),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    # 모델 생성\n",
    "    # rf_model = RandomForestRegressor(**rf_params)\n",
    "    lgbm_model = LGBMRegressor(**lgbm_params)\n",
    "    xgb_model = XGBRegressor(**xgb_params)\n",
    "    models = [ lgbm_model, xgb_model]\n",
    "    # rf_model,\n",
    "    # TimeSeriesSplit 사용\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    meta_X_train = create_meta_features(models, X_train, y_train_log, tscv)\n",
    "    \n",
    "    # 메타 모델 학습 및 평가\n",
    "    meta_model_ridge = Ridge(alpha=1.0, random_state=42)\n",
    "    meta_model_ridge.fit(meta_X_train, y_train_log)\n",
    "    train_preds_log = meta_model_ridge.predict(meta_X_train)\n",
    "    train_preds = np.expm1(train_preds_log)  # 로그 역변환\n",
    "    rmse = mean_squared_error(y_train, train_preds, squared=False)\n",
    "    return rmse\n",
    "\n",
    "# 8. Optuna 스터디 실행\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "# 9. 최적 하이퍼파라미터 추출 및 모델 생성\n",
    "best_params = study.best_params\n",
    "\n",
    "# rf_best = RandomForestRegressor(\n",
    "#     n_estimators=best_params[\"rf_n_estimators\"],\n",
    "#     max_depth=best_params[\"rf_max_depth\"],\n",
    "#     min_samples_leaf=best_params[\"rf_min_samples_leaf\"],\n",
    "#     min_samples_split=best_params[\"rf_min_samples_split\"],\n",
    "#     max_features=best_params[\"rf_max_features\"],\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "lgbm_best = LGBMRegressor(\n",
    "    n_estimators=best_params[\"lgbm_n_estimators\"],\n",
    "    max_depth=best_params[\"lgbm_max_depth\"],\n",
    "    learning_rate=best_params[\"lgbm_learning_rate\"],\n",
    "    num_leaves=best_params[\"lgbm_num_leaves\"],\n",
    "    subsample=best_params[\"lgbm_subsample\"],\n",
    "    colsample_bytree=best_params[\"lgbm_colsample_bytree\"],\n",
    "    reg_alpha=best_params[\"lgbm_reg_alpha\"],\n",
    "    reg_lambda=best_params[\"lgbm_reg_lambda\"],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_best = XGBRegressor(\n",
    "    n_estimators=best_params[\"xgb_n_estimators\"],\n",
    "    max_depth=best_params[\"xgb_max_depth\"],\n",
    "    learning_rate=best_params[\"xgb_learning_rate\"],\n",
    "    subsample=best_params[\"xgb_subsample\"],\n",
    "    colsample_bytree=best_params[\"xgb_colsample_bytree\"],\n",
    "    gamma=best_params[\"xgb_gamma\"],\n",
    "    reg_alpha=best_params[\"xgb_reg_alpha\"],\n",
    "    reg_lambda=best_params[\"xgb_reg_lambda\"],\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "models_best = [ lgbm_best, xgb_best]\n",
    "# rf_best,\n",
    "# 10. TimeSeriesSplit 정의\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 11. 메타 피처 생성 및 메타 모델 학습\n",
    "meta_X_train_best = create_meta_features(models_best, X_train, y_train_log, tscv)\n",
    "\n",
    "# 12. 메타 모델 학습 (Ridge와 LGBM 둘 다)\n",
    "meta_model_ridge = Ridge(alpha=1.0, random_state=42)\n",
    "meta_model_lgbm = LGBMRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "meta_model_ridge.fit(meta_X_train_best, y_train_log)\n",
    "meta_model_lgbm.fit(meta_X_train_best, y_train_log)\n",
    "\n",
    "# 13. 훈련 성능 평가\n",
    "train_preds_ridge_log = meta_model_ridge.predict(meta_X_train_best)\n",
    "train_preds_ridge = np.expm1(train_preds_ridge_log)\n",
    "rmse_train_ridge = mean_squared_error(y_train, train_preds_ridge, squared=False)\n",
    "print(f\"Ridge 메타모델 Train RMSE (원래 스케일): {rmse_train_ridge:.4f}\")\n",
    "\n",
    "train_preds_lgbm_log = meta_model_lgbm.predict(meta_X_train_best)\n",
    "train_preds_lgbm = np.expm1(train_preds_lgbm_log)\n",
    "rmse_train_lgbm = mean_squared_error(y_train, train_preds_lgbm, squared=False)\n",
    "print(f\"LGBM 메타모델 Train RMSE (원래 스케일): {rmse_train_lgbm:.4f}\")\n",
    "\n",
    "# 14. 테스트 데이터 예측\n",
    "meta_X_test_best = get_test_meta_features(models_best, X_train, y_train_log, X_test)\n",
    "\n",
    "# Ridge 예측\n",
    "final_predictions_log_ridge = meta_model_ridge.predict(meta_X_test_best)\n",
    "final_predictions_ridge = np.expm1(final_predictions_log_ridge)  # 로그 역변환\n",
    "rounded_preds_ridge = np.round(final_predictions_ridge).astype(int)\n",
    "\n",
    "# LGBM 예측\n",
    "final_predictions_log_lgbm = meta_model_lgbm.predict(meta_X_test_best)\n",
    "final_predictions_lgbm = np.expm1(final_predictions_log_lgbm)  # 로그 역변환\n",
    "rounded_preds_lgbm = np.round(final_predictions_lgbm).astype(int)\n",
    "\n",
    "# 15. 제출파일 저장\n",
    "submission_ridge = pd.DataFrame({'target': rounded_preds_ridge})\n",
    "submission_ridge.to_csv('submission_optuna_ridge2.csv', index=False)\n",
    "print(\"submission_optuna_ridge.csv 파일이 생성되었습니다.\")\n",
    "\n",
    "submission_lgbm = pd.DataFrame({'target': rounded_preds_lgbm})\n",
    "submission_lgbm.to_csv('submission_optuna_lgbm2.csv', index=False)\n",
    "print(\"submission_optuna_lgbm.csv 파일이 생성되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d0ae63c-ffba-4278-8329-6f9aabb75421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타 모델 학습 RMSE: 7584.4036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain & Predict:  33%|█████████████████████████▎                                                  | 1/3 [00:47<01:35, 47.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 635467, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 68659.895346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain & Predict: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [01:15<00:00, 25.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# meta_model = Ridge(alpha=1.0, random_state=42) # 메타 모델 생성\n",
    "# meta_model.fit(meta_X_train, y_train)\n",
    "# meta_X_train = create_meta_features(models, X_train, y_train, kf)\n",
    "# meta_X_test = get_test_meta_features(models, X_train, y_train, X_test)\n",
    "# final_predictions = meta_model.predict(meta_X_test)\n",
    "\n",
    "# # 메타 모델 훈련 데이터 예측\n",
    "# meta_train_preds = meta_model.predict(meta_X_train)\n",
    "\n",
    "# RMSE 계산\n",
    "# rmse_meta_train = mean_squared_error(y_train, meta_train_preds, squared=False)\n",
    "# print(f\"메타 모델 학습 RMSE: {rmse_meta_train:.4f}\")\n",
    "\n",
    "# # 테스트 데이터 예측\n",
    "# meta_X_test = get_test_meta_features(models, X_train, y_train, X_test)\n",
    "# final_predictions = meta_model.predict(meta_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9c550bb6-f0df-49ac-8f0d-1de8b807bf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타 모델 학습 RMSE: 10780.4784\n"
     ]
    }
   ],
   "source": [
    "def stacking_cv_rmse(models, meta_models, X, y, kf):\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_tr, X_val = X[train_idx], X[val_idx]\n",
    "        y_tr, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # 베이스 모델 OOF 메타 피처\n",
    "        meta_tr = create_meta_features_advanced(models, X_tr, y_tr, kf)\n",
    "        meta_val = np.column_stack([\n",
    "            m.fit(X_tr, y_tr).predict(X_val) for m in models\n",
    "        ])\n",
    "\n",
    "        # 메타 모델 예측값 평균\n",
    "        final_val_pred = np.zeros(len(y_val))\n",
    "        for meta_model in meta_models.values():\n",
    "            meta_model.fit(meta_tr, y_tr)\n",
    "            final_val_pred += meta_model.predict(meta_val) * (1/len(meta_models))\n",
    "        \n",
    "        rmses.append(mean_squared_error(y_val, final_val_pred, squared=False))\n",
    "\n",
    "    return np.mean(rmses), np.std(rmses)\n",
    "\n",
    "mean_rmse, std_rmse = stacking_cv_rmse(models, meta_predictions, X_train, y_train, kf)\n",
    "print(f\"스태킹 앙상블 CV RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c899d2f-3b02-413e-9754-0947ecc6f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_final_predictions = np.round(final_predictions)\n",
    "submission = pd.DataFrame({\n",
    "    'target': final_predictions\n",
    "})\n",
    "submission.to_csv('submission_5ensemble_imeanse.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
